from os import listdir
from xml.etree import ElementTree
from numpy import zeros
from numpy import asarray
from numpy import expand_dims
from matplotlib import pyplot
from matplotlib.patches import Rectangle
from mrcnn.config import Config
from mrcnn.model import MaskRCNN
from mrcnn.model import mold_image
from mrcnn.utils import Dataset
import math
import cv2
import numpy as np
import pytesseract

pytesseract.pytesseract.tesseract_cmd = "C:\Program Files\Tesseract-OCR/tesseract.exe"

# class that defines and loads the texy dataset
class TextDataset(Dataset):
    # load the dataset definitions
    def load_dataset(self, dataset_dir, is_train=True):
        # define one class
        self.add_class("dataset", 1, "text")
        # define data locations
        images_dir = dataset_dir + '/images/'
        annotations_dir = dataset_dir + '/annots/'
        # find all images
        for filename in listdir(images_dir):
            print('filename1',filename)
            # removing image extension from image id
            head, sep, tail = filename.partition('.')
            print ('head',head)
            # extract image id
            image_id=head
            img_path = images_dir + filename
            ann_path = annotations_dir + image_id + '.xml'
            # add to dataset
            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)

    # load all bounding boxes for an image
    def extract_boxes(self, filename):
        # load and parse the file
        root = ElementTree.parse(filename)
        boxes = list()
        # extract each bounding box
        for box in root.findall('.//bndbox'):
            xmin = int(box.find('xmin').text)
            ymin = int(box.find('ymin').text)
            xmax = int(box.find('xmax').text)
            ymax = int(box.find('ymax').text)
            coors = [xmin, ymin, xmax, ymax]
            boxes.append(coors)
        # extract image dimensions
        width = int(root.find('.//size/width').text)
        height = int(root.find('.//size/height').text)
        return boxes, width, height

    # load the masks for an image
    def load_mask(self, image_id):
        # get details of image
        info = self.image_info[image_id]
        # define box file location
        path = info['annotation']
        # load XML
        boxes, w, h = self.extract_boxes(path)
        # create one array for all masks, each on a different channel
        masks = zeros([h, w, len(boxes)], dtype='uint8')
        # create masks
        class_ids = list()
        for i in range(len(boxes)):
            box = boxes[i]
            row_s, row_e = box[1], box[3]
            col_s, col_e = box[0], box[2]
            masks[row_s:row_e, col_s:col_e, i] = 1
            class_ids.append(self.class_names.index('text'))
        return masks, asarray(class_ids, dtype='int32')

    # load an image reference
    def image_reference(self, image_id):
        info = self.image_info[image_id]
        return info['path']


# define the prediction configuration
class PredictionConfig(Config):
    # define the name of the configuration
    NAME = "kangaroo_cfg"
    # number of classes (background + text)
    NUM_CLASSES = 1 + 1
    # simplify GPU config
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1


# plot a number of photos with ground truth and predictions
def Predicted(dataset, model, cfg, n_images=1):
    # load image and mask
    y1=0
    x1=0
    y2=0
    x2=0
    image = dataset.load_image(0)

    for i in range(n_images):
        # load the image and mask
        image = dataset.load_image(i)
        mask, _ = dataset.load_mask(i)
        # convert pixel values (e.g. center)
        scaled_image = mold_image(image, cfg)
        # convert image into one sample
        sample = expand_dims(scaled_image, 0)
        # make prediction
        yhat = model.detect(sample, verbose=0)[0]
        # getting scores
        score = [yhat['scores']]
        # axis stores the coordinates of the bix predicted
        axis = []

        print(yhat['scores'])

        for j in range(mask.shape[2]):
            # displaying mask with alpha blurring
            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)
        # get the context for drawing boxes
        pyplot.subplot(n_images,1,i+1)
        # plot raw pixel data
        pyplot.imshow(image)
        pyplot.title('Predicted')
        ax = pyplot.gca()
        # plot each box
        for box in yhat['rois']:
            # get coordinates
            y1, x1, y2, x2 = box
            # calculate width and height of the box
            width, height = x2 - x1, y2 - y1
            # create the shape
            rect = Rectangle((x1, y1), width, height, fill=False, color='red')
            # draw the box

            ax.add_patch(rect)
            axis.append([y1, y2, x1, x2])

    # show the figure

    pyplot.show()
    print('axis',axis)
    print("confidence score: ",score)
    print(y1, x1, y2, x2 )
    return(y1, x1, y2, x2 ,image,axis,score)


#MAIN::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
# Load image and threshold
image = cv2.imread(r'D:\DIP PROJECT\text_dataset\test1\img (82).jpeg')
# for drawing line
image1=cv2.imread(r'D:\DIP PROJECT\text_dataset\test1\img (82).jpeg')
gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
gray = cv2.bitwise_not(gray)

# detect edges using canny and the use hough to plot lines for angle detection
img_edges = cv2.Canny(gray, 100, 100, apertureSize=3)
lines = cv2.HoughLinesP(img_edges, 1, math.pi / 180.0, 100)
angles = []

# calculate angle through slope of line
for x1, y1, x2, y2 in lines[0]:
    cv2.line(image1, (x1, y1), (x2, y2), (255, 0, 0), 3)
    angle = math.degrees(math.atan2(y2 - y1, x2 - x1))
    angles.append(angle)

# rotate image through possible angles: 0 90 270
median_angle = float(np.median(angles))
if median_angle == -90:
    img_rotate = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)
elif median_angle == 90:
    img_rotate = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
else:
    img_rotate = image[:]


cv2.imwrite(r'D:\DIP PROJECT\text_dataset\test1\images\img (1).jpeg', img_rotate)

# loading image to test data set
test_set = TextDataset()
test_set.load_dataset('D:\DIP PROJECT/text_dataset/test1', is_train=False)
test_set.prepare()
print('Test: %d' % len(test_set.image_ids))
# create config
cfg = PredictionConfig()
# define the model
model = MaskRCNN(mode='inference', model_dir='./', config=cfg)
# load model weights
model_path = 'project_model.h5'
model.load_weights(model_path, by_name=True)

# plotting the predicted result
y1, x1, y2, x2,image,axis,scores =Predicted(test_set, model, cfg)
print('axis_after', axis)

# taking the box of max score
h,w,d=image.shape
s0=scores[0][0]
# s1=np.max(scores)
for s in range(len(scores[0])):
    if scores[0][s]>=s0:
        s0=scores[0][s]
        y1=axis[s][0]
        y2=axis[s][1]
        x1=axis[s][2]
        x2=axis[s][3]

        print(y1, y2, x1, x2)

width, height = x2 - x1, y2 - y1

# plotting box of max score
print('user defined')
figure, ax = pyplot.subplots(1)
ax.imshow(image)
rect = Rectangle((x1, y1), width, height, fill=False, color='red')
ax.add_patch(rect)
pyplot.show()

# saving the resulting cooridianted and rotated image in a file for further use
def file_save(y1, x1, y2, x2,image):
    #file saving and img save
    f=open("D:\DIP PROJECT\COORD_TXT\img.txt", "r+")
    f.truncate()
    f.write(repr(y1))
    f.write("\n")

    f.write(repr(x1))
    f.write("\n")

    f.write(repr(y2))
    f.write("\n")

    f.write(repr(x2))
    f.write("\n")

    f=open("D:\DIP PROJECT\COORD_TXT\img.txt", "r")
    y11=f.readline()
    x11=f.readline()
    y22=f.readline()
    x22=f.readline()
    print(int(y11))
    print(int(x11))
    print(int(y22))
    print(int(x22))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    cv2.imwrite("D:\DIP PROJECT\COORD_TXT\img.jpg",image)


file_save(y1, x1, y2, x2,image)
